{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce8fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets transformers tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df588275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 18:55:29.616380: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9373] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-26 18:55:29.616429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-26 18:55:29.617574: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1534] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-26 18:55:29.624700: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3070 Laptop GPU, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 18:55:32.145825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 18:55:32.155824: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 18:55:32.155859: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 18:55:32.156159: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import os, random, tensorflow as tf\n",
    "from datasets import load_dataset\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "#enable training on gpu with quantized weights \n",
    "set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d04675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download dataset\n",
    "dataset = load_dataset(\"stanfordnlp/sst2\")\n",
    "\n",
    "#download gpt2 tokenizer and manually set pad token (gpt2 doesn't have one by default so we use the end of string token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8650ae2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n",
      "2025-04-26 18:55:34.115778: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 18:55:34.115853: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 18:55:34.115874: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 18:55:34.241536: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 18:55:34.241579: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 18:55:34.241587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-04-26 18:55:34.241614: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-04-26 18:55:34.241631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5318 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#set max token sequence length and define the tokenizer function\n",
    "MAX_LEN = 128\n",
    "def tokenize_fn(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "#adjust batch size higher or lower based on available VRAM. 32 has good performance on 8gb\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#create train and valudation datasets based on the ones included in sst2\n",
    "train_ds = dataset[\"train\"].map(tokenize_fn).to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "val_ds = dataset[\"validation\"].map(tokenize_fn).to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"label\"],\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb17e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2ForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFGPT2ForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/2105 [..............................] - ETA: 14:13 - loss: 2.6016 - accuracy: 0.5521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 18:56:02.865014: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f61f295d3e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-04-26 18:56:02.865076: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Laptop GPU, Compute Capability 8.6\n",
      "2025-04-26 18:56:02.874783: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-04-26 18:56:02.900814: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:467] Loaded cuDNN version 90000\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745693762.961943   24144 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2105/2105 [==============================] - 937s 434ms/step - loss: 0.2789 - accuracy: 0.8843 - val_loss: 0.2320 - val_accuracy: 0.9140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./gpt2_sst2_finetuned/tokenizer_config.json',\n",
       " './gpt2_sst2_finetuned/special_tokens_map.json',\n",
       " './gpt2_sst2_finetuned/vocab.json',\n",
       " './gpt2_sst2_finetuned/merges.txt',\n",
       " './gpt2_sst2_finetuned/added_tokens.json',\n",
       " './gpt2_sst2_finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load pre trained model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",            #load pretrained gpt2 weights\n",
    "    num_labels=2       #set number of output classes (binary classification)\n",
    ")\n",
    "\n",
    "\n",
    "#adam optimizer with small learning rate for fine tuning\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)   \n",
    "\n",
    "#using sparse categorical crossentropy for the loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  \n",
    "\n",
    "#compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "#train model\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=1      # train for 1 epoch because model is pre trained and any more causes overfitting\n",
    ")\n",
    "\n",
    "# save fine tuned model and tokenizer to file\n",
    "save_dir = \"./gpt2_sst2_finetuned\"\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b4add2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2ForSequenceClassification.\n",
      "\n",
      "All the layers of TFGPT2ForSequenceClassification were initialized from the model checkpoint at ./gpt2_sst2_finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simple Reviews\n",
      "\n",
      "I loved it.                                                             Positive  (Pos: 99.7% / Neg: 0.3%)\n",
      "Amazing experience!                                                     Positive  (Pos: 99.7% / Neg: 0.3%)\n",
      "Absolutely fantastic.                                                   Positive  (Pos: 99.9% / Neg: 0.1%)\n",
      "Best film I've seen this year.                                          Positive  (Pos: 99.8% / Neg: 0.2%)\n",
      "Terrible and boring.                                                    Negative  (Pos: 0.1% / Neg: 99.9%)\n",
      "Worst movie ever.                                                       Negative  (Pos: 0.3% / Neg: 99.7%)\n",
      "Undeniably awful.                                                       Negative  (Pos: 0.2% / Neg: 99.8%)\n",
      "Complete disaster.                                                      Negative  (Pos: 0.8% / Neg: 99.2%)\n",
      "\n",
      "Ambiguous Reviews\n",
      "\n",
      "It was okay, not great but not bad either.                              Positive  (Pos: 96.4% / Neg: 3.6%)\n",
      "Some parts worked, others fell flat.                                    Negative  (Pos: 0.4% / Neg: 99.6%)\n",
      "I liked the idea more than the execution.                               Positive  (Pos: 90.0% / Neg: 10.0%)\n",
      "Decent performances, weak story.                                        Negative  (Pos: 4.8% / Neg: 95.2%)\n",
      "Beautiful visuals, confusing plot.                                      Positive  (Pos: 95.0% / Neg: 5.0%)\n",
      "Good soundtrack, but I wouldn't watch it again.                         Negative  (Pos: 41.8% / Neg: 58.2%)\n",
      "Enjoyable moments mixed with long boring scenes.                        Positive  (Pos: 56.6% / Neg: 43.4%)\n",
      "Neither terrible nor amazing, just a movie.                             Negative  (Pos: 4.2% / Neg: 95.8%)\n",
      "\n",
      "Confusing Positive Reviews\n",
      "\n",
      "I hated the theater, but the movie was actually pretty good.            Positive  (Pos: 99.1% / Neg: 0.9%)\n",
      "The plot was terrible, yet somehow I found it highly entertaining.      Positive  (Pos: 98.5% / Neg: 1.5%)\n",
      "It was a strange film, but the acting made it a fantastic experience.   Positive  (Pos: 99.6% / Neg: 0.4%)\n",
      "The first half was slow, but it ended really strong.                    Positive  (Pos: 99.2% / Neg: 0.8%)\n",
      "Boring to start, but surprisingly emotional by the end.                 Positive  (Pos: 92.9% / Neg: 7.1%)\n",
      "Terrible pacing, but unforgettable characters.                          Positive  (Pos: 95.6% / Neg: 4.4%)\n",
      "Some parts were confusing, although I loved the visuals.                Positive  (Pos: 90.3% / Neg: 9.7%)\n",
      "I regret going, but I kind of liked the movie.                          Positive  (Pos: 99.1% / Neg: 0.9%)\n",
      "\n",
      "Confusing Negative Reviews\n",
      "\n",
      "I loved the director's past work, but this movie was a total joke.      Negative  (Pos: 4.5% / Neg: 95.5%)\n",
      "The trailer looked great, but the movie itself was terrible.            Negative  (Pos: 0.4% / Neg: 99.6%)\n",
      "I enjoyed the first few minutes, but the rest was boring and predictable.  Negative  (Pos: 1.1% / Neg: 98.9%)\n",
      "It had a great cast, but they couldn't save the awful writing.          Negative  (Pos: 0.6% / Neg: 99.4%)\n",
      "Stunning visuals couldn't hide the fact that it was a complete mess.    Negative  (Pos: 5.8% / Neg: 94.2%)\n",
      "The premise was interesting, but the execution was painfully bad.       Negative  (Pos: 0.4% / Neg: 99.6%)\n",
      "I wanted to like it so badly, but it was just too slow and dull.        Negative  (Pos: 0.2% / Neg: 99.9%)\n",
      "There were some funny moments, but overall it was a huge waste of time.  Negative  (Pos: 0.7% / Neg: 99.3%)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "#load saved model and tokenizer\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"./gpt2_sst2_finetuned\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./gpt2_sst2_finetuned\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "#declare some test data\n",
    "simple_reviews = [\n",
    "    \"I loved it.\",\n",
    "    \"Amazing experience!\",\n",
    "    \"Absolutely fantastic.\",\n",
    "    \"Best film I've seen this year.\",\n",
    "    \"Terrible and boring.\",\n",
    "    \"Worst movie ever.\",\n",
    "    \"Undeniably awful.\",\n",
    "    \"Complete disaster.\"\n",
    "]\n",
    "\n",
    "ambiguous_reviews = [\n",
    "    \"It was okay, not great but not bad either.\",\n",
    "    \"Some parts worked, others fell flat.\",\n",
    "    \"I liked the idea more than the execution.\",\n",
    "    \"Decent performances, weak story.\",\n",
    "    \"Beautiful visuals, confusing plot.\",\n",
    "    \"Good soundtrack, but I wouldn't watch it again.\",\n",
    "    \"Enjoyable moments mixed with long boring scenes.\",\n",
    "    \"Neither terrible nor amazing, just a movie.\",\n",
    "]\n",
    "\n",
    "confusing_positive_reviews = [\n",
    "    \"I hated the theater, but the movie was actually pretty good.\",\n",
    "    \"The plot was terrible, yet somehow I found it highly entertaining.\",\n",
    "    \"It was a strange film, but the acting made it a fantastic experience.\",\n",
    "    \"The first half was slow, but it ended really strong.\",\n",
    "    \"Boring to start, but surprisingly emotional by the end.\",\n",
    "    \"Terrible pacing, but unforgettable characters.\",\n",
    "    \"Some parts were confusing, although I loved the visuals.\",\n",
    "    \"I regret going, but I kind of liked the movie.\",\n",
    "]\n",
    "\n",
    "confusing_negative_reviews = [\n",
    "    \"I loved the director's past work, but this movie was a total joke.\",\n",
    "    \"The trailer looked great, but the movie itself was terrible.\",\n",
    "    \"I enjoyed the first few minutes, but the rest was boring and predictable.\",\n",
    "    \"It had a great cast, but they couldn't save the awful writing.\",\n",
    "    \"Stunning visuals couldn't hide the fact that it was a complete mess.\",\n",
    "    \"The premise was interesting, but the execution was painfully bad.\",\n",
    "    \"I wanted to like it so badly, but it was just too slow and dull.\",\n",
    "    \"There were some funny moments, but overall it was a huge waste of time.\",\n",
    "]\n",
    "\n",
    "# function to run inference on a group of sentences\n",
    "def run_inference(group_name, sentences):\n",
    "    print(f\"\\n{group_name}\\n\")\n",
    "    \n",
    "    #tokenize the sentences\n",
    "    encodings = tokenizer(\n",
    "        sentences,\n",
    "        padding=True,             #force pad all sentences to max length\n",
    "        truncation=True,           #truncate if sentence is longer than max length\n",
    "        return_tensors=\"tf\",       #return tensorflow tensors\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    #forward pass through the model\n",
    "    logits = model(encodings).logits\n",
    "\n",
    "    #apply softmax to convert logits to class probabilities\n",
    "    probs = tf.nn.softmax(logits, axis=-1).numpy()\n",
    "\n",
    "    #print predictions\n",
    "    for sent, p in zip(sentences, probs):\n",
    "        pred_label = \"Positive\" if p[1] > p[0] else \"Negative\"  #decide based on which probability is higher\n",
    "        print(f\"{sent:70s}  {pred_label}  (Pos: {p[1]:.1%} / Neg: {p[0]:.1%})\")\n",
    "\n",
    "# run inference on the sentences\n",
    "run_inference(\"Simple Reviews\", simple_reviews)\n",
    "run_inference(\"Ambiguous Reviews\", ambiguous_reviews)\n",
    "run_inference(\"Confusing Positive Reviews\", confusing_positive_reviews)\n",
    "run_inference(\"Confusing Negative Reviews\", confusing_negative_reviews)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
